{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization of Russian Regions Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☑ Basic class\n",
    "\n",
    "☑ Read etalon names from YAML file\n",
    "\n",
    "☐ Test threshold values\n",
    "\n",
    "☐ Add additional data for every normalized name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from fuzzywuzzy import fuzz\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('d:/coding/0_be_precise/reg_normalizer/data/interim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_yaml(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = yaml.safe_load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "etalon_regions = read_yaml('regions_etalon_v2.0.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homoglyph substitution dictionary (Latin to Cyrillic)\n",
    "LATIN_TO_CYRILLIC = {\n",
    "    'A': 'А', 'B': 'В', 'C': 'С', 'E': 'Е', 'H': 'Н',\n",
    "    'I': 'І', 'J': 'Ј', 'K': 'К', 'M': 'М', 'O': 'О',\n",
    "    'P': 'Р', 'S': 'С', 'T': 'Т', 'X': 'Х', 'Y': 'У',\n",
    "    'a': 'а', 'b': 'в', 'c': 'с', 'e': 'е', 'i': 'і',\n",
    "    'j': 'ј', 'k': 'к', 'm': 'м', 'o': 'о', 'p': 'р',\n",
    "    's': 'с', 't': 'т', 'x': 'х', 'y': 'у'\n",
    "}\n",
    "\n",
    "def preprocess_name(name: str) -> str:\n",
    "    \"\"\"Normalize and clean region names for comparison.\"\"\"\n",
    "    if not isinstance(name, str):\n",
    "        return ''\n",
    "    \n",
    "    for latin, cyrillic in LATIN_TO_CYRILLIC.items():\n",
    "        name = name.replace(latin, cyrillic)\n",
    "    \n",
    "    name = re.sub(r'[-–—]+', ' ', name)  \n",
    "    name = re.sub(r'\\s+', ' ', name).strip().lower()\n",
    "    return name\n",
    "\n",
    "def stem_region_name(name: str) -> str:\n",
    "    \"\"\"Stem Russian words using Snowball stemmer\"\"\"\n",
    "    if not name:\n",
    "        return ''\n",
    "    stemmer = SnowballStemmer('russian')\n",
    "    words = name.split()\n",
    "    return ' '.join([stemmer.stem(word) for word in words])\n",
    "\n",
    "class RegionMatcher:\n",
    "    def __init__(self, etalon_regions):\n",
    "        self.etalon = list(etalon_regions)\n",
    "        # Precompute both preprocessed and stemmed versions\n",
    "        self.preprocessed_etalon = [\n",
    "            (region, preprocess_name(region), stem_region_name(preprocess_name(region))) \n",
    "            for region in self.etalon\n",
    "        ]\n",
    "    \n",
    "    def find_best_match(self, input_name, \n",
    "                       weights=None, \n",
    "                       approach_weights=None,\n",
    "                       threshold=70):\n",
    "        \"\"\"Find best match using combined approaches\"\"\"\n",
    "        # Set default weights if not provided\n",
    "        weights = weights or {'levenshtein': 0.5, 'token_set': 0.5}\n",
    "        approach_weights = approach_weights or {'original': 0.5, 'stemmed': 0.5}\n",
    "        \n",
    "        # Preprocess input in both versions\n",
    "        preprocessed_input = preprocess_name(input_name)\n",
    "        stemmed_input = stem_region_name(preprocessed_input)\n",
    "        \n",
    "        best_match = None\n",
    "        best_score = 0\n",
    "        \n",
    "        for etalon_name, etalon_preprocessed, etalon_stemmed in self.preprocessed_etalon:\n",
    "            # Calculate original approach scores\n",
    "            lev_original = fuzz.ratio(preprocessed_input, etalon_preprocessed)\n",
    "            ts_original = fuzz.token_set_ratio(preprocessed_input, etalon_preprocessed)\n",
    "            original_score = (weights['levenshtein'] * lev_original + \n",
    "                             weights['token_set'] * ts_original)\n",
    "            \n",
    "            lev_stemmed = fuzz.ratio(stemmed_input, etalon_stemmed)\n",
    "            ts_stemmed = fuzz.token_set_ratio(stemmed_input, etalon_stemmed)\n",
    "            stemmed_score = (weights['levenshtein'] * lev_stemmed + \n",
    "                            weights['token_set'] * ts_stemmed)\n",
    "\n",
    "            total_score = (approach_weights['original'] * original_score +\n",
    "                          approach_weights['stemmed'] * stemmed_score)\n",
    "            \n",
    "            if total_score > best_score:\n",
    "                best_score = total_score\n",
    "                best_match = etalon_name\n",
    "        \n",
    "        return best_match if best_score >= threshold else None\n",
    "    \n",
    "    def match_dataframe(self, df, column_name, **kwargs):\n",
    "        \"\"\"Apply matching to an entire DataFrame column\"\"\"\n",
    "        df['matched_region'] = df[column_name].apply(\n",
    "            lambda x: self.find_best_match(x, **kwargs)\n",
    "        )\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize with etalon regions\n",
    "etalon_regions = [\n",
    "    'Московская область',\n",
    "    'Свердловская область',\n",
    "    'Санкт-Петербург',\n",
    "    'Республика Татарстан',\n",
    "    'Алтайский край',\n",
    "    'Республика Алтай',\n",
    "    'Республика Татарстан'\n",
    "]\n",
    "\n",
    "matcher = RegionMatcher(etalon_regions)\n",
    "\n",
    "# Sample DataFrame with messy data\n",
    "data = pd.DataFrame({\n",
    "    'region': [\n",
    "        'московск Обл',        # Shortened form\n",
    "        'свердловск',          # Without 'область'\n",
    "        'петербург',           # Shortened\n",
    "        'Mосковская област',   # Latin 'M' + typo\n",
    "        'татарстан респ.',     # Abbreviation\n",
    "        'Свердлов обл',         # Different ending\n",
    "        'aлтайский к',\n",
    "        'Республика     Алтай'\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 region        matched_region\n",
      "0          московск Обл    Московская область\n",
      "1            свердловск  Свердловская область\n",
      "2             петербург       Санкт-Петербург\n",
      "3     Mосковская област    Московская область\n",
      "4       татарстан респ.  Республика Татарстан\n",
      "5          Свердлов обл  Свердловская область\n",
      "6           aлтайский к        Алтайский край\n",
      "7  Республика     Алтай      Республика Алтай\n"
     ]
    }
   ],
   "source": [
    "# Match with emphasis on stemmed approach\n",
    "result = matcher.match_dataframe(\n",
    "    data,\n",
    "    'region',\n",
    "    weights={'levenshtein': 0.4, 'token_set': 0.6},\n",
    "    approach_weights={'original': 0.3, 'stemmed': 0.7},\n",
    "    threshold=70\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
